{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info(trabajo_link):\n",
    "    \"\"\"El input es un enlace que dirige a una única oferta de trabajo. Devuelve un tuple con la información más relevante: descripción del anuncio y del trabajo\"\"\"\n",
    "    anuncio_list = []\n",
    "    description_list = []\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    try:\n",
    "        response = get_page(trabajo_link)\n",
    "        result_page = BeautifulSoup(response.content,'lxml')\n",
    "        anuncio_list = get_anuncio_list(result_page)\n",
    "        description_list = get_job_description(result_page)\n",
    "        empresa_name = get_name_empresa(result_page)\n",
    "        output = unify_lists([empresa_name, anuncio_list, description_list])\n",
    "        return output\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        print(\"It didn't work\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anuncio_list(result_page):\n",
    "    '''This function recover the information concerning ID Empleo, Categoria, Ubicación, etc'''\n",
    "    anuncio_list = []\n",
    "    for info in result_page.find_all('div', class_='smallListingInfo'):\n",
    "        if not 'Primera' in info.get_text(): #Exclude 'Primera Publicacion'\n",
    "            if not 'Contrato' in info.get_text():\n",
    "                anuncio_item = info.get_text()\n",
    "                anuncio_item = anuncio_item[anuncio_item.find(':')+2:]\n",
    "                anuncio_list.append(anuncio_item.replace('\\n',''))  #Get items without \\n\n",
    "                #anuncio_list.append(info.get_text().replace('\\n',''))\n",
    "    return anuncio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(result_page):\n",
    "    text = ''\n",
    "    for paragraph in result_page.find_all('p'):\n",
    "        if paragraph.text != \"\\n\":\n",
    "            text = text + paragraph.text\n",
    "    text = clean_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_empresa(result_page):\n",
    "    Enterprise_information = result_page.find('div', class_ = 'compProfileInfo')\n",
    "    return Enterprise_information.find('strong').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import unidecode\n",
    "    text = text.lower().replace('\\n','') #Get items without \\n\n",
    "    text = re.sub(\"(\\(\\w+\\))\", '', text) #Delete parenthesis\n",
    "    text = unidecode.unidecode(text) #Delete accents\n",
    "    text = re.sub('[^A-Za-z0-9\\s]','',text) #Delete anything but letters, numbers and spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_lists(job_list):\n",
    "    new_list = []\n",
    "    new_list.append(job_list[0])\n",
    "    for element in job_list[1]:\n",
    "        new_list.append(element)\n",
    "    new_list.append(job_list[2])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trabajo_link = \"https://www.trabajopolis.bo/oferta-de-trabajo-y-empleo-en-bolivia/695472/Analista-de-Tesorería.html?searchId=1545862649.53&page=1\"\n",
    "response = get_page(trabajo_link)\n",
    "result_page = BeautifulSoup(response.content,'lxml')\n",
    "anuncio_list = get_anuncio_list(result_page)\n",
    "#description_list = get_job_description(result_page)\n",
    "#empresa_name = get_name_empresa(result_page)\n",
    "#output = unify_lists([empresa_name, anuncio_list, description_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trabajopolis(job_description):\n",
    "    import time\n",
    "    \"\"\" A partir de una (o más) palabras claves  \"\"\"\n",
    "    trabajos_list = []\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    for job in job_description:\n",
    "        url = \"http://www.trabajopolis.bo/search-results-jobs/?action=search&listing_type%5Bequal%5D=Job&listings_order_by=desc&JobCategory%5Bmulti_like%5D%5B%5D=&CityBolivia%5Bmulti_like%5D%5B%5D=&PostedWithin%5Bmulti_like%5D%5B%5D=&EmploymentType%5Bmulti_like%5D%5B%5D=&keywords%5Bany_words%5D=\"+ job + \"&page=1&listings_per_page=1000\"\n",
    "        url = \"https://www.trabajopolis.bo/search-results-jobs/?action=search&listing_type%5Bequal%5D=Job&listings_order_by=desc&JobCategory%5Bmulti_like%5D%5B%5D=&CityBolivia%5Bmulti_like%5D%5B%5D=&PostedWithin%5Bmulti_like%5D%5B%5D=&EmploymentType%5Bmulti_like%5D%5B%5D=&keywords%5Bany_words%5D=\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            print(\"The request response cycle was successful\")\n",
    "            results_page = BeautifulSoup(response.content,'lxml')\n",
    "            #trabajo_list = list()\n",
    "            trabajos = results_page.findAll('td',{\"class\":\"anuncio-estandar-content\"})\n",
    "            for anuncio in trabajos:\n",
    "                trabajo_link = anuncio.find('a').get('href')\n",
    "                trabajo_name = anuncio.find('b').get_text()\n",
    "                print(trabajo_link)\n",
    "             #   trabajo_list.append((trabajo_name,trabajo_link))\n",
    "            #for trabajo in trabajo_list:\n",
    "                output = get_job_info(trabajo_link)\n",
    "                trabajos_list.append((output,trabajo_name,trabajo_link))\n",
    "            #I need to create a list that save all the extracted data\n",
    "        else:\n",
    "            print(\"The request response cycle work didn't work\")\n",
    "        time.sleep(10) \n",
    "    return trabajos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trabajopolis2():\n",
    "    trabajos_list = []\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    url = \"https://www.trabajopolis.bo/search-results-jobs/?searchId=1546400657&action=search&page=1&listings_per_page=1000\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"The request response cycle was successful\")\n",
    "        results_page = BeautifulSoup(response.content,'lxml')\n",
    "        trabajos = results_page.findAll('td',{\"class\":\"anuncio-estandar-content\"})\n",
    "        for anuncio in trabajos:\n",
    "            trabajo_link = anuncio.find('a').get('href')\n",
    "            trabajo_name = anuncio.find('b').get_text()\n",
    "            print(trabajo_link)\n",
    "            output = get_job_info(trabajo_link)\n",
    "            trabajos_list.append((output,trabajo_name,trabajo_link))\n",
    "            #I need to create a list that save all the extracted data\n",
    "    else:\n",
    "        print(\"The request response cycle work didn't work\")\n",
    "    return trabajos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names = [\"analista\", \"desarrollador\", \"programador\", \"quimico\", \"finanzas\", \"mensajero\", \"albañil\"]\n",
    "job_names1 = [\"Administración\", \"Oficina\", \"Atención\", \"Cliente\", \"Banca\", \"Contabilidad\"]\n",
    "job_names2 = [\"Economía\", \"Dirección\", \"Gerencia\", \"Diseño\", \"Marketing\", \"Ventas\"]\n",
    "job_names3 = [\"Vendedor\", \"Medicina\", \"Profesor\", \"Técnico\", \"Educación\", \"Legal\", \"Asesoría\", \"Turismo\"]\n",
    "job_names4 = ['Personal', 'conocimientos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Results = trabajopolis2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "outfile = open(\"/Users/Roberto/Documents/Python Scripts/Machine Learning Projects/Labor Market/trabajo123.csv\", 'a',newline='')\n",
    "writer = csv.writer(outfile)\n",
    "try:\n",
    "    for i in range(len(Results)):\n",
    "        csvRow = []\n",
    "        for cell in Results[i][0]:\n",
    "            #print(cell)\n",
    "           csvRow.append(cell)\n",
    "        csvRow.append(Results[i][1])\n",
    "        csvRow.append(Results[i][2])\n",
    "        #print(csvRow)\n",
    "        writer.writerow(csvRow)\n",
    "finally:\n",
    "    outfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
